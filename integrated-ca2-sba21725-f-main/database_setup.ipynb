{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18da5b7f-1428-458e-b61a-d526c3b62ea1",
   "metadata": {},
   "source": [
    "# Database Setup\n",
    "\n",
    "This notebook is intended to setup a MongoDB and a MySql databases.\n",
    "\n",
    "Run this Notebook only once to create the required tables and collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5265e386-eca9-49ee-af8b-f63add406669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python==9.1.0 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from -r ./requirements_db.txt (line 1)) (9.1.0)\n",
      "Requirement already satisfied: pandas==2.2.3 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from -r ./requirements_db.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: pymongo==4.10.1 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from -r ./requirements_db.txt (line 3)) (4.10.1)\n",
      "Requirement already satisfied: pymysql==1.1.1 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from -r ./requirements_db.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: sqlalchemy==2.0.36 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from -r ./requirements_db.txt (line 5)) (2.0.36)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from pandas==2.2.3->-r ./requirements_db.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from pandas==2.2.3->-r ./requirements_db.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from pandas==2.2.3->-r ./requirements_db.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from pandas==2.2.3->-r ./requirements_db.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from pymongo==4.10.1->-r ./requirements_db.txt (line 3)) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from sqlalchemy==2.0.36->-r ./requirements_db.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from sqlalchemy==2.0.36->-r ./requirements_db.txt (line 5)) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/hduser/micromamba/envs/bigdata/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas==2.2.3->-r ./requirements_db.txt (line 2)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r \"./requirements_db.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fe472f6-8161-4289-86b9-b8ed9c81b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "import pymysql \n",
    "\n",
    "from sqlalchemy import create_engine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ed589-197a-414e-a568-993d0352e6c5",
   "metadata": {},
   "source": [
    "# PART I - MongoDB Setup\n",
    "\n",
    "Although Mongo would create the Database and Collections when I first insert data into it, I choose to create the collections beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148869e7-033c-4027-a2bd-f4974ffb0358",
   "metadata": {},
   "source": [
    "## Connect to MongoDB instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c4a812-2ae6-4cea-9f64-00594dba91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGOURI = os.getenv('MONGOURI')\n",
    "MONGODB = os.getenv('MONGODB')\n",
    "\n",
    "client = MongoClient(MONGOURI, server_api=ServerApi('1'))\n",
    "\n",
    "# Select database by name.\n",
    "# If database does not exist it will create a new one.\n",
    "db = client[MONGODB]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950eab1f-e8f9-4dce-a05c-8357d5c5b9e8",
   "metadata": {},
   "source": [
    "## Create the required Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab688c0e-b10e-49c3-bbc4-138c68154fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockprice = db.create_collection(\"stockprice\")\n",
    "stocktweet = db.create_collection(\"stocktweet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fc12d-fd2c-47f0-81c3-c4e42e8fb662",
   "metadata": {},
   "source": [
    "# PART II - MySQL Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3d60a-c382-44b7-9e35-bd717a7503f0",
   "metadata": {},
   "source": [
    "## 1. Connect to the MySQL instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "585d6b50-8693-468e-b25e-bf6c5923fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from the environment variables\n",
    "hostname = os.getenv('MYSQLHOST')\n",
    "port=int(os.getenv('MYSQLPORT'))\n",
    "username = os.getenv('MYSQLUSR')\n",
    "password = os.getenv('MYSQLPASS')\n",
    "database_name = os.getenv('MYSQLDB') \n",
    "ca_cert_path = '../ca.pem'\n",
    "\n",
    "# Create MySQL connection object\n",
    "connection = pymysql.connect( \n",
    "    host=hostname, \n",
    "    port=port, \n",
    "    user=username, \n",
    "    password=password, \n",
    "    database=database_name, \n",
    "    ssl={'ca': ca_cert_path} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cfa53c2-800e-45dc-9b05-d92ac1a58bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SQLAlchemy engine for MySQL\n",
    "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{hostname}:{port}/{database_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf689d7-bf1e-4fa6-9ac1-88f3d57e02ac",
   "metadata": {},
   "source": [
    "## 2. Define table names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a13c8720-e397-4605-bf7b-5a90581754a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    \"Stocktweet\",\n",
    "    \"Stockprice\",\n",
    "    \"Sentiment\",\n",
    "    \"Company\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4739615-c53b-481a-9106-5541874ab038",
   "metadata": {},
   "source": [
    "## 3. Drop tables if exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac5922cb-6513-4c8d-8e51-71b229fc77e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Stocktweet' dropped successfully\n",
      "Table 'Stockprice' dropped successfully\n",
      "Table 'Sentiment' dropped successfully\n",
      "Table 'Company' dropped successfully\n"
     ]
    }
   ],
   "source": [
    "# Drop all tables\n",
    "for table in tables:\n",
    "    query = \"DROP TABLE IF EXISTS {};\".format(table)\n",
    "\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(query)\n",
    "        print(\"Table '{}' dropped successfully\".format(table))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e33ca-4c40-4df8-ac60-a1701ba2a6e6",
   "metadata": {},
   "source": [
    "## 4. Create the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65fb6cb9-06cf-4729-8a3a-4397fb6f6f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully.\n",
      "Table created successfully.\n",
      "Table created successfully.\n",
      "Table created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Query\n",
    "table_queries = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Company (\n",
    "        ticker VARCHAR(6) PRIMARY KEY,\n",
    "        name VARCHAR(80)\n",
    "    );\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Stocktweet (\n",
    "        id INT PRIMARY KEY,\n",
    "        date DATE,\n",
    "        ticker VARCHAR(6),\n",
    "        tweet TEXT,\n",
    "        CONSTRAINT fk_ticker_stocktweet\n",
    "            FOREIGN KEY (ticker) REFERENCES Company(ticker)\n",
    "            ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\",\n",
    "          \n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Stockprice (\n",
    "        id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "        ticker VARCHAR(6),\n",
    "        Date DATE,\n",
    "        Open DECIMAL(12, 6),\n",
    "        High DECIMAL(12, 6),\n",
    "        Low DECIMAL(12, 6),\n",
    "        Close DECIMAL(12, 6),\n",
    "        AdjClose DECIMAL(12, 6),\n",
    "        Volume BIGINT,\n",
    "        CONSTRAINT fk_ticker_stockprice\n",
    "            FOREIGN KEY (ticker) REFERENCES Company(ticker)\n",
    "            ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Sentiment (\n",
    "        id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "        ticker VARCHAR(6),\n",
    "        date DATE,\n",
    "        score DECIMAL(12,6),\n",
    "        CONSTRAINT fk_ticker_sentiment\n",
    "            FOREIGN KEY (ticker) REFERENCES Company(ticker)\n",
    "            ON DELETE CASCADE\n",
    "    );\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "for table_query in table_queries:\n",
    "    with connection.cursor() as cursor:\n",
    "        cursor.execute(table_query)\n",
    "        print(\"Table created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db922bf-438c-474e-80b2-4d10d80065c8",
   "metadata": {},
   "source": [
    "# PART III - Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ac960-348c-4083-82cb-9188d8e43100",
   "metadata": {},
   "source": [
    "# A. Load Data into MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d97851-838f-473f-9de2-9eabd6767e8e",
   "metadata": {},
   "source": [
    "## 1. Company Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "288271ab-34c1-4eb4-b065-c227a13d4d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "tickers = [\n",
    "    \"AAPL\",\n",
    "    \"AMT\",\n",
    "    \"AMZN\",\n",
    "    \"BA\",\n",
    "    \"BABA\",\n",
    "    \"BAC\",\n",
    "    \"BKNG\",\n",
    "    \"BRK.A\",\n",
    "    \"BRK.B\",\n",
    "    \"CCL\",\n",
    "    \"CVX\",\n",
    "    \"DIS\",\n",
    "    \"FB\",\n",
    "    \"GOOG\",\n",
    "    \"GOOGL\",\n",
    "    \"HD\",\n",
    "    \"JNJ\",\n",
    "    \"JPM\",\n",
    "    \"KO\",\n",
    "    \"LOW\",\n",
    "    \"MA\",\n",
    "    \"MCD\",\n",
    "    \"META\",\n",
    "    \"MSFT\",\n",
    "    \"NFLX\",\n",
    "    \"NKE\",\n",
    "    \"NVDA\",\n",
    "    \"PFE\",\n",
    "    \"PG\",\n",
    "    \"PYPL\",\n",
    "    \"SBUX\",\n",
    "    \"TM\",\n",
    "    \"TSLA\",\n",
    "    \"TSM\",\n",
    "    \"UNH\",\n",
    "    \"UPS\",\n",
    "    \"V\",\n",
    "    \"WMT\",\n",
    "    \"XOM\"\n",
    "]\n",
    "\n",
    "# Insert multiple rows of data\n",
    "insert_query = '''\n",
    "INSERT INTO Company (ticker)\n",
    "VALUES (%s);\n",
    "'''\n",
    "\n",
    "\n",
    "with connection.cursor() as cursor:\n",
    "    cursor.executemany(insert_query, tickers)\n",
    "    connection.commit()\n",
    "    print(\"Tickers inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224e527-ec3a-4eff-b464-48dbee7f350e",
   "metadata": {},
   "source": [
    "# 2. Stocktweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87b373ce-31ef-498f-81a6-bf79d351fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stocktweet loaded into MySQL table successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the data types for stocktweet columns\n",
    "dtype_dict = {\n",
    "    'id': 'int64',           \n",
    "    'ticker': 'str',        \n",
    "    'tweet': 'str'\n",
    "}\n",
    "\n",
    "# Load stocktweet\n",
    "df = pd.read_csv('./data/stocktweet/stocktweet.csv', dtype=dtype_dict, parse_dates=['date'])\n",
    "\n",
    "# format date column\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')\n",
    "\n",
    "# Insert the data into the MySQL table\n",
    "df.to_sql(\"Stocktweet\", engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"Stocktweet loaded into MySQL table successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce03c7a0-7712-45ca-983f-5c40c7547999",
   "metadata": {},
   "source": [
    "# 3. Stockprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b487b09d-e8fa-4953-b196-06ee7ae89880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data types for stockprice columns\n",
    "dtype_dict = {       \n",
    "    'Open': 'float',    \n",
    "    'High': 'float',\n",
    "    'Low': 'float',\n",
    "    'Close': 'float',\n",
    "    'Adj Close': 'float',\n",
    "    'Volume': 'int'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5ab5362-4723-40b3-91d1-4668b76924fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABNB\n",
      "MA\n",
      "UPS\n",
      "BRK-A\n",
      "BAC\n",
      "KO\n",
      "TM\n",
      "MSFT\n",
      "BA\n",
      "BKNG\n",
      "FB\n",
      "PG\n",
      "AMZN\n",
      "BRK-B\n",
      "XOM\n",
      "NFLX\n",
      "LOW\n",
      "SBUX\n",
      "META\n",
      "MCD\n",
      "CCL\n",
      "V\n",
      "UNH\n",
      "TSLA\n",
      "AAPL\n",
      "NKE\n",
      "BABA\n",
      "GOOGL\n",
      "PFE\n",
      "HD\n",
      "CVX\n",
      "NVDA\n",
      "WMT\n",
      "PYPL\n",
      "DIS\n",
      "JNJ\n",
      "AMT\n",
      "GOOG\n",
      "JPM\n",
      "TSM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "folder_path = Path('./data/stockprice/')\n",
    "\n",
    "for file_path in folder_path.iterdir():\n",
    "    if (file_path.is_file()) and (file_path.name.rstrip(\".csv\").replace(\"-\",\".\") in tickers):  # Check if it’s a file and a ticker exists\n",
    "        print(file_path.name.rstrip(\".csv\"))\n",
    "        df = pd.read_csv(\"./data/stockprice/{}\".format(file_path.name), dtype=dtype_dict, parse_dates=['Date'])\n",
    "        \n",
    "        # Rename column 'Adj Close' to 'AdjClose'\n",
    "        df.rename(columns={'Adj Close': 'AdjClose'}, inplace=True)\n",
    "        \n",
    "        df['ticker'] = file_path.name.rstrip(\".csv\").replace(\"-\", \".\")\n",
    "        \n",
    "        # format date column\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "        df.to_sql(\"Stockprice\", engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26452cf-3604-4645-8188-6637966ac13c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
